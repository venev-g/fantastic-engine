{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab912706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet pinecone-client pinecone pinecone-text pinecone-notebooks \"numpy>=2.0.0,<3.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff193bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet langchain-huggingface sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cc2cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a272e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "api_key = st.secrets[\"PINECONE_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c72ab96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import PineconeHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bcb01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "index_name = \"langchain-hybrid-search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28173b",
   "metadata": {},
   "source": [
    "### Initialize Pinecone client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc61faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99826cef",
   "metadata": {},
   "source": [
    "### Creating a new index if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "760d1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,     # dimension of dense vector \n",
    "        metric=\"dotproduct\",  # sparse values are supported only for dotproduct\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f192d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index ('langchain-hybrid-search', <pinecone.data.index.Index object at 0x717b7a8ba240>) created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'dotproduct',\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "print(f\"Index {index_name, index} created.\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f056ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone_text.sparse import BM25Encoder   # for sparse vectorization\n",
    "\n",
    "bm25_encoder = BM25Encoder().default() # TF-IDF technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30074cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pinecone_text.sparse.bm25_encoder.BM25Encoder object at 0x717b0bc079e0>\n"
     ]
    }
   ],
   "source": [
    "print(bm25_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73462057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt_tab', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b03f4e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 209.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x717b0bc079e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List of sample sentences\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"A journey of a thousand miles begins with a single step.\",\n",
    "    \"To be or not to be, that is the question.\",\n",
    "    \"All that glitters is not gold.\",\n",
    "    \"The only thing we have to fear is fear itself.\",\n",
    "]\n",
    "\n",
    "# TF-IDF values on these sentences\n",
    "bm25_encoder.fit(sentences)\n",
    "\n",
    "# store in a json file\n",
    "bm25_encoder.dump(\"bm25_values.json\")\n",
    "\n",
    "# load the json file\n",
    "bm25_encoder.load(\"bm25_values.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffef585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeHybridSearchRetriever(embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), sparse_encoder=<pinecone_text.sparse.bm25_encoder.BM25Encoder object at 0x717b0bc079e0>, index=<pinecone.data.index.Index object at 0x717b7a8ba240>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Create LangChain compatible embeddings wrapper for our SentenceTransformer model\n",
    "hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "retriever = PineconeHybridSearchRetriever(\n",
    "    embeddings=hf_embeddings,\n",
    "    sparse_encoder=bm25_encoder,\n",
    "    index=index\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "682fc3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccb656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.733545}, page_content='The only thing we have to fear is fear itself.'),\n",
       " Document(metadata={'score': 0.147580177}, page_content='To be or not to be, that is the question.'),\n",
       " Document(metadata={'score': 0.0415346622}, page_content='A journey of a thousand miles begins with a single step.'),\n",
       " Document(metadata={'score': 0.032869257}, page_content='The quick brown fox jumps over the lazy dog.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\n",
    "    \"What is the only thing we have to fear?\",\n",
    "    # k=3,\n",
    "    # sparse_k=3,\n",
    "    # dense_k=3,\n",
    "    # hybrid_k=3,\n",
    "    # include_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
