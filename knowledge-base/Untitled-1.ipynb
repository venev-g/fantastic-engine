{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa12fa9",
   "metadata": {},
   "source": [
    "# Document Heading Extraction Improvements\n",
    "\n",
    "This notebook focuses on improving the extraction of headings from various document types, with special attention to first page headings that are often missed due to different formatting or structural characteristics. We'll enhance the existing document analyzer to better identify and extract headings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb118ac",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "First, let's import all the necessary libraries for document processing and heading extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Any, Optional, Union\n",
    "\n",
    "# Document processing libraries\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "import tabula\n",
    "\n",
    "# Word document processing\n",
    "import docx\n",
    "from docx.document import Document as DocxDocument\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.text.paragraph import Paragraph\n",
    "\n",
    "# Image processing (for visual content extraction)\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "print(\"All required libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d8e37",
   "metadata": {},
   "source": [
    "## 2. Load and Analyze Document Structure\n",
    "\n",
    "We'll build on the existing DocumentAnalyzer class to improve its heading detection capabilities. First, let's enhance the document structure analysis to better identify potential headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f90d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedDocumentAnalyzer:\n",
    "    \"\"\"Enhanced class to analyze document structure with improved heading detection.\"\"\"\n",
    "\n",
    "    def __init__(self, debug_mode=False):\n",
    "        \"\"\"Initialize the enhanced document analyzer.\n",
    "        \n",
    "        Args:\n",
    "            debug_mode: Whether to print detailed debugging information\n",
    "        \"\"\"\n",
    "        self.debug_mode = debug_mode\n",
    "        # Track statistics about document structure\n",
    "        self.stats = {\n",
    "            'total_headings': 0,\n",
    "            'first_page_headings': 0,\n",
    "            'missed_headings_recovered': 0\n",
    "        }\n",
    "        \n",
    "    def load_document(self, file_path: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Load document from file path and return structured content with enhanced heading detection.\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the document file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with structured document content\n",
    "        \"\"\"\n",
    "        # Get file extension\n",
    "        _, ext = os.path.splitext(file_path)\n",
    "        ext = ext.lower()\n",
    "        \n",
    "        if ext == '.pdf':\n",
    "            return self._process_pdf(file_path)\n",
    "        elif ext in ['.html', '.htm']:\n",
    "            return self._process_html(file_path)\n",
    "        elif ext in ['.txt', '.md']:\n",
    "            return self._process_text(file_path)\n",
    "        elif ext in ['.docx', '.doc']:\n",
    "            return self._process_word(file_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "\n",
    "    def _log_debug(self, message):\n",
    "        \"\"\"Log debug information if debug mode is enabled.\"\"\"\n",
    "        if self.debug_mode:\n",
    "            print(f\"DEBUG: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab72032",
   "metadata": {},
   "source": [
    "### 2.1 Enhanced PDF Processing\n",
    "\n",
    "PDF documents often have headings with different formatting, especially on the first page (title page). Let's enhance the PDF processor to better detect these headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_pdf(self, file_path: str) -> Dict:\n",
    "    \"\"\"Process PDF documents with enhanced heading detection.\n",
    "    \n",
    "    This method focuses on better detecting:\n",
    "    1. First page headings (often missed due to different formatting)\n",
    "    2. Headings identified by font size and style rather than explicit structure\n",
    "    3. Headings with no explicit level indicators\n",
    "    \"\"\"\n",
    "    document_structure = {\n",
    "        'metadata': {'source': file_path, 'type': 'pdf'},\n",
    "        'elements': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Use PyPDF2 to extract font information for better heading detection\n",
    "        pdf_reader = PyPDF2.PdfReader(file_path)\n",
    "        first_page_content = None\n",
    "        total_pages = len(pdf_reader.pages)\n",
    "        \n",
    "        self._log_debug(f\"PDF has {total_pages} pages\")\n",
    "        \n",
    "        # First pass: extract text from each page with font details using PyPDF2\n",
    "        page_texts_with_fonts = []\n",
    "        \n",
    "        # Extract first page separately for special processing\n",
    "        if total_pages > 0:\n",
    "            first_page = pdf_reader.pages[0]\n",
    "            first_page_content = first_page.extract_text()\n",
    "            page_texts_with_fonts.append(first_page_content)\n",
    "            \n",
    "            # Special handling for first page - look for potential title and headings\n",
    "            self._extract_first_page_headings(first_page_content, document_structure)\n",
    "        \n",
    "        # Now use unstructured for better extraction\n",
    "        try:\n",
    "            # Check if poppler is available\n",
    "            import shutil\n",
    "            if not shutil.which('pdftotext'):\n",
    "                print(\"Warning: poppler-utils not found in PATH. Installing...\")\n",
    "                import subprocess\n",
    "                subprocess.run([\"apt-get\", \"update\"], check=True)\n",
    "                subprocess.run([\"apt-get\", \"install\", \"-y\", \"poppler-utils\"], check=True)\n",
    "                print(\"poppler-utils installed successfully\")\n",
    "\n",
    "            # Read PDF and extract text with unstructured library\n",
    "            elements = partition_pdf(\n",
    "                filename=file_path,\n",
    "                extract_images=True,\n",
    "                infer_table_structure=True\n",
    "            )\n",
    "\n",
    "            # Extract tables separately using tabula\n",
    "            tables = tabula.read_pdf(file_path, pages='all')\n",
    "            \n",
    "            # Track page numbers for better heading hierarchy detection\n",
    "            current_page = 1\n",
    "            page_heading_count = {}\n",
    "            \n",
    "            # Process elements and categorize them with enhanced heading detection\n",
    "            for element in elements:\n",
    "                elem_type = str(type(element)).lower()\n",
    "                element_data = {\n",
    "                    'content': str(element),\n",
    "                    'type': None,\n",
    "                    'page': getattr(element, 'metadata', {}).get('page_number', None)\n",
    "                }\n",
    "                \n",
    "                # Update current page if available\n",
    "                if element_data['page'] is not None:\n",
    "                    current_page = element_data['page']\n",
    "                    \n",
    "                # Enhanced heading detection logic\n",
    "                if 'title' in elem_type or 'heading' in elem_type:\n",
    "                    element_data['type'] = 'heading'\n",
    "                    \n",
    "                    # Try to infer heading level\n",
    "                    heading_text = str(element)\n",
    "                    inferred_level = self._infer_heading_level(heading_text, current_page)\n",
    "                    element_data['level'] = inferred_level\n",
    "                    \n",
    "                    # Track headings by page\n",
    "                    page_heading_count[current_page] = page_heading_count.get(current_page, 0) + 1\n",
    "                    \n",
    "                    # Update stats\n",
    "                    self.stats['total_headings'] += 1\n",
    "                    if current_page == 1:\n",
    "                        self.stats['first_page_headings'] += 1\n",
    "                        \n",
    "                elif 'table' in elem_type:\n",
    "                    element_data['type'] = 'table'\n",
    "                elif 'image' in elem_type:\n",
    "                    element_data['type'] = 'image' \n",
    "                    # Try OCR on images to find possible headings in images\n",
    "                    self._process_image_for_headings(element, document_structure)\n",
    "                elif 'text' in elem_type:\n",
    "                    # Enhanced text analysis to detect headings by formatting\n",
    "                    heading_result = self._detect_heading_in_text(str(element), current_page)\n",
    "                    \n",
    "                    if heading_result['is_heading']:\n",
    "                        element_data['type'] = 'heading'\n",
    "                        element_data['level'] = heading_result['level']\n",
    "                        self.stats['total_headings'] += 1\n",
    "                        self.stats['missed_headings_recovered'] += 1\n",
    "                        if current_page == 1:\n",
    "                            self.stats['first_page_headings'] += 1\n",
    "                    # Check if it's strikeout or highlighted\n",
    "                    elif '~~' in str(element) or '--' in str(element):\n",
    "                        element_data['type'] = 'strikeout'\n",
    "                    elif any(marker in str(element) for marker in ['**', '__', '>>']): \n",
    "                        element_data['type'] = 'highlight'\n",
    "                    else:\n",
    "                        element_data['type'] = 'paragraph'\n",
    "\n",
    "                document_structure['elements'].append(element_data)\n",
    "\n",
    "            # Add tables from tabula to our elements list\n",
    "            for i, table in enumerate(tables):\n",
    "                document_structure['elements'].append({\n",
    "                    'content': table,\n",
    "                    'type': 'table',\n",
    "                    'pandas_table': True,\n",
    "                    'table_id': i\n",
    "                })\n",
    "                \n",
    "            self._log_debug(f\"Heading distribution by page: {page_heading_count}\")\n",
    "            \n",
    "            # Post-process to ensure first page headings are properly represented\n",
    "            self._ensure_first_page_headings(document_structure)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self._log_debug(f\"Error in unstructured PDF processing: {e}\")\n",
    "            # Fallback method using PyPDF2 if unstructured fails\n",
    "            self._process_pdf_fallback(pdf_reader, document_structure)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        document_structure['elements'].append({\n",
    "            'content': f\"Error processing PDF file: {str(e)}\",\n",
    "            'type': 'paragraph',\n",
    "        })\n",
    "\n",
    "    return document_structure\n",
    "    \n",
    "EnhancedDocumentAnalyzer._process_pdf = _process_pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e976f",
   "metadata": {},
   "source": [
    "### 2.2 Additional Helper Methods for PDF Heading Extraction\n",
    "\n",
    "Let's implement the helper methods for enhanced heading detection in PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8688aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_first_page_headings(self, first_page_text: str, document_structure: Dict):\n",
    "    \"\"\"Extract potential headings from the first page of a document.\"\"\"\n",
    "    if not first_page_text:\n",
    "        return\n",
    "        \n",
    "    self._log_debug(\"Analyzing first page text for headings\")\n",
    "    \n",
    "    # Split into lines\n",
    "    lines = first_page_text.split('\\n')\n",
    "    \n",
    "    # Process the first few lines (likely to contain title and headings)\n",
    "    for i, line in enumerate(lines[:10]):  # Focus on first 10 lines\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # Possible title/heading heuristics:\n",
    "        # 1. All caps line is likely a heading\n",
    "        # 2. Short line centered on page likely a heading\n",
    "        # 3. Line ending with colon without ending punctuation might be a heading\n",
    "        \n",
    "        if len(line) > 3:  # Skip very short lines\n",
    "            is_heading = False\n",
    "            level = 1  # Default to top level for first page\n",
    "            \n",
    "            if line.isupper() and len(line) > 5:  # All caps, likely a heading\n",
    "                is_heading = True\n",
    "                level = 1 if i < 3 else 2  # First few all-caps lines are likely top level\n",
    "            \n",
    "            elif len(line) < 60 and not any(p in line for p in ['.', '?', '!']):\n",
    "                # Short line without sentence-ending punctuation\n",
    "                if i < 3:  # First few lines\n",
    "                    is_heading = True\n",
    "                    level = 1 if i == 0 else 2\n",
    "                elif line.endswith(':'):  # Line ending with colon\n",
    "                    is_heading = True\n",
    "                    level = 2\n",
    "                    \n",
    "            if is_heading:\n",
    "                # Add as a heading\n",
    "                document_structure['elements'].append({\n",
    "                    'content': line,\n",
    "                    'type': 'heading',\n",
    "                    'level': level,\n",
    "                    'page': 1,\n",
    "                    'extracted_from': 'first_page_analysis'\n",
    "                })\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Detected first page heading: {line}\")\n",
    "\n",
    "def _infer_heading_level(self, heading_text: str, page_number: int = 1) -> int:\n",
    "    \"\"\"Infer heading level based on text characteristics.\"\"\"\n",
    "    # Simple heuristics to determine heading level\n",
    "    if page_number == 1:\n",
    "        if len(heading_text) < 30 and heading_text.isupper():\n",
    "            return 1  # Main title\n",
    "        else:\n",
    "            return 2  # Subtitle on first page\n",
    "    \n",
    "    # For other pages, use text characteristics\n",
    "    heading_text = heading_text.strip()\n",
    "    \n",
    "    # Check for numbered headings like \"1.\", \"1.1\", \"1.1.1\"\n",
    "    if re.match(r'^\\d+\\.', heading_text):\n",
    "        return 1\n",
    "    elif re.match(r'^\\d+\\.\\d+', heading_text):\n",
    "        return 2\n",
    "    elif re.match(r'^\\d+\\.\\d+\\.\\d+', heading_text):\n",
    "        return 3\n",
    "        \n",
    "    # Check for all caps (often indicates higher level headings)\n",
    "    if heading_text.isupper():\n",
    "        return 1\n",
    "        \n",
    "    # Default to level 2 for most detected headings\n",
    "    return 2\n",
    "\n",
    "def _detect_heading_in_text(self, text: str, page_number: int = 1) -> Dict:\n",
    "    \"\"\"Determine if a text element might be a heading based on characteristics.\"\"\"\n",
    "    text = text.strip()\n",
    "    result = {'is_heading': False, 'level': 0}\n",
    "    \n",
    "    # Skip very long text - headings tend to be shorter\n",
    "    if len(text) > 100:\n",
    "        return result\n",
    "        \n",
    "    # Skip text with multiple sentences if not on first page\n",
    "    if page_number > 1 and len(re.findall(r'[.!?]', text)) > 1:\n",
    "        return result\n",
    "    \n",
    "    # Strong heading indicators\n",
    "    if re.match(r'^(chapter|section|title|appendix)\\s+\\w+', text.lower()):\n",
    "        result['is_heading'] = True\n",
    "        result['level'] = 1\n",
    "        return result\n",
    "        \n",
    "    # Numbered heading patterns\n",
    "    if re.match(r'^\\d+\\.\\s+[A-Z]', text):  # Like \"1. TITLE\"\n",
    "        result['is_heading'] = True\n",
    "        result['level'] = 1\n",
    "        return result\n",
    "    \n",
    "    if re.match(r'^\\d+\\.\\d+\\.\\s+[A-Z]', text):  # Like \"1.1. Title\"\n",
    "        result['is_heading'] = True\n",
    "        result['level'] = 2\n",
    "        return result\n",
    "    \n",
    "    # Formatting indicators\n",
    "    if text.isupper() and 5 < len(text) < 70:  # ALL CAPS text of reasonable length\n",
    "        result['is_heading'] = True\n",
    "        result['level'] = 1\n",
    "        return result\n",
    "        \n",
    "    # First page special cases\n",
    "    if page_number == 1:\n",
    "        # Short standalone text at the top of the first page\n",
    "        if len(text) < 80 and not any(p in text for p in ['.', ',', ';', '?', '!']):\n",
    "            result['is_heading'] = True\n",
    "            result['level'] = 1 if len(text) < 40 else 2\n",
    "            return result\n",
    "    \n",
    "    return result\n",
    "\n",
    "def _process_image_for_headings(self, image_element, document_structure: Dict):\n",
    "    \"\"\"Try to extract text from images to find headings.\"\"\"\n",
    "    # This would use OCR to find text in images\n",
    "    # For now, we'll just add a placeholder comment\n",
    "    # In a complete implementation, we would:\n",
    "    # 1. Extract the image\n",
    "    # 2. Use pytesseract to get text\n",
    "    # 3. Analyze text for potential headings\n",
    "    self._log_debug(\"Image processing for headings would occur here\")\n",
    "\n",
    "def _process_pdf_fallback(self, pdf_reader, document_structure: Dict):\n",
    "    \"\"\"Fallback method to extract content from PDF using PyPDF2.\"\"\"\n",
    "    self._log_debug(\"Using PDF fallback method\")\n",
    "    \n",
    "    for i, page in enumerate(pdf_reader.pages):\n",
    "        page_text = page.extract_text()\n",
    "        page_number = i + 1\n",
    "        \n",
    "        # For first page, do special processing\n",
    "        if page_number == 1:\n",
    "            self._extract_first_page_headings(page_text, document_structure)\n",
    "        \n",
    "        # Simple paragraph splitting\n",
    "        paragraphs = [p for p in page_text.split('\\n\\n') if p.strip()]\n",
    "        \n",
    "        for para in paragraphs:\n",
    "            para = para.strip()\n",
    "            if not para:\n",
    "                continue\n",
    "                \n",
    "            # Check if paragraph might be a heading\n",
    "            heading_info = self._detect_heading_in_text(para, page_number)\n",
    "            \n",
    "            if heading_info['is_heading']:\n",
    "                document_structure['elements'].append({\n",
    "                    'content': para,\n",
    "                    'type': 'heading',\n",
    "                    'level': heading_info['level'],\n",
    "                    'page': page_number,\n",
    "                    'extracted_from': 'fallback_method'\n",
    "                })\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "            else:\n",
    "                document_structure['elements'].append({\n",
    "                    'content': para,\n",
    "                    'type': 'paragraph',\n",
    "                    'page': page_number\n",
    "                })\n",
    "                \n",
    "def _ensure_first_page_headings(self, document_structure: Dict):\n",
    "    \"\"\"Make sure we have at least one heading from the first page.\"\"\"\n",
    "    first_page_headings = [e for e in document_structure['elements'] \n",
    "                           if e['type'] == 'heading' and \n",
    "                              (e.get('page') == 1 or e.get('page') is None)]\n",
    "    \n",
    "    if not first_page_headings:\n",
    "        self._log_debug(\"No first page headings found, looking for potential candidates\")\n",
    "        # Look for potential headings in first page paragraphs\n",
    "        first_page_paragraphs = [e for e in document_structure['elements']\n",
    "                                if e['type'] == 'paragraph' and\n",
    "                                   (e.get('page') == 1 or e.get('page') is None)]\n",
    "        \n",
    "        # Take the first short paragraph as a potential heading\n",
    "        for para in first_page_paragraphs:\n",
    "            content = para['content']\n",
    "            if len(content) < 80 and not any(p in content for p in ['.', ',', ';', '?', '!']):\n",
    "                # Convert to heading\n",
    "                para['type'] = 'heading'\n",
    "                para['level'] = 1\n",
    "                para['extracted_from'] = 'fallback_first_page'\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Converted paragraph to heading: {content}\")\n",
    "                break\n",
    "\n",
    "# Add methods to the EnhancedDocumentAnalyzer class\n",
    "EnhancedDocumentAnalyzer._extract_first_page_headings = _extract_first_page_headings\n",
    "EnhancedDocumentAnalyzer._infer_heading_level = _infer_heading_level\n",
    "EnhancedDocumentAnalyzer._detect_heading_in_text = _detect_heading_in_text\n",
    "EnhancedDocumentAnalyzer._process_image_for_headings = _process_image_for_headings\n",
    "EnhancedDocumentAnalyzer._process_pdf_fallback = _process_pdf_fallback\n",
    "EnhancedDocumentAnalyzer._ensure_first_page_headings = _ensure_first_page_headings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630195b5",
   "metadata": {},
   "source": [
    "## 3. Enhance Heading Detection Logic for Different Document Types\n",
    "\n",
    "Now let's enhance the processors for other document types, starting with the Word document processor, which needs similar improvements for heading detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_word(self, file_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Enhanced Word document processor with improved heading detection.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the Word document\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with structured document content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        document_structure = {\n",
    "            'metadata': {'source': file_path, 'type': 'docx'},\n",
    "            'elements': []\n",
    "        }\n",
    "        \n",
    "        # Load document with python-docx\n",
    "        document = docx.Document(file_path)\n",
    "        \n",
    "        # Extract metadata early\n",
    "        try:\n",
    "            core_properties = document.core_properties\n",
    "            document_structure['metadata']['title'] = core_properties.title\n",
    "            document_structure['metadata']['author'] = core_properties.author\n",
    "            document_structure['metadata']['created'] = str(core_properties.created)\n",
    "            document_structure['metadata']['modified'] = str(core_properties.modified)\n",
    "        except Exception as e:\n",
    "            self._log_debug(f\"Error extracting document properties: {e}\")\n",
    "        \n",
    "        # First pass: gather font statistics to determine normal vs. heading text\n",
    "        font_sizes = []\n",
    "        for paragraph in document.paragraphs:\n",
    "            for run in paragraph.runs:\n",
    "                if run.font.size:\n",
    "                    # Convert to points if needed and store\n",
    "                    size = run.font.size.pt if hasattr(run.font.size, 'pt') else run.font.size / 12700\n",
    "                    font_sizes.append(size)\n",
    "        \n",
    "        # Calculate stats if we have enough samples\n",
    "        normal_font_size = None\n",
    "        if font_sizes:\n",
    "            # Use mode or median as normal font size\n",
    "            from statistics import median, mode\n",
    "            try:\n",
    "                normal_font_size = mode(font_sizes)\n",
    "            except:\n",
    "                normal_font_size = median(font_sizes)\n",
    "            self._log_debug(f\"Detected normal font size: {normal_font_size}\")\n",
    "        \n",
    "        # Track if we're in first page content\n",
    "        first_page_headings_found = False\n",
    "        \n",
    "        # Process paragraphs\n",
    "        for i, paragraph in enumerate(document.paragraphs):\n",
    "            text = paragraph.text.strip()\n",
    "            if not text:\n",
    "                continue\n",
    "                \n",
    "            # Determine if paragraph is likely a heading\n",
    "            is_heading = False\n",
    "            heading_level = 0\n",
    "            \n",
    "            # Check paragraph style - most reliable way\n",
    "            if paragraph.style and 'heading' in paragraph.style.name.lower():\n",
    "                is_heading = True\n",
    "                try:\n",
    "                    # Try to extract level from style name (e.g., \"Heading 1\" -> 1)\n",
    "                    heading_match = re.search(r'heading\\s+(\\d+)', paragraph.style.name.lower())\n",
    "                    if heading_match:\n",
    "                        heading_level = int(heading_match.group(1))\n",
    "                    else:\n",
    "                        # Default based on order of appearance\n",
    "                        heading_level = 1 if i < 5 else 2\n",
    "                except:\n",
    "                    heading_level = 1 if i < 5 else 2\n",
    "            \n",
    "            # If not detected by style, check alternative indicators\n",
    "            elif not is_heading:\n",
    "                # Check if it's a short paragraph near the beginning (potential title)\n",
    "                if i < 5 and len(text) < 100:\n",
    "                    # Check font attributes\n",
    "                    has_larger_font = False\n",
    "                    is_bold = False\n",
    "                    \n",
    "                    for run in paragraph.runs:\n",
    "                        if run.bold:\n",
    "                            is_bold = True\n",
    "                        if run.font.size and normal_font_size:\n",
    "                            # Convert to points if needed\n",
    "                            size = run.font.size.pt if hasattr(run.font.size, 'pt') else run.font.size / 12700\n",
    "                            if size > normal_font_size * 1.2:  # 20% larger than normal\n",
    "                                has_larger_font = True\n",
    "                    \n",
    "                    # Mark as heading if formatting suggests it\n",
    "                    if has_larger_font or is_bold:\n",
    "                        is_heading = True\n",
    "                        heading_level = 1 if i < 2 else 2\n",
    "                \n",
    "                # Check for numbered heading patterns\n",
    "                if not is_heading:\n",
    "                    # Look for patterns like \"1.\", \"1.1\", \"Chapter 1\", etc.\n",
    "                    if (re.match(r'^\\d+\\.', text) or \n",
    "                        re.match(r'^chapter\\s+\\d+', text.lower()) or\n",
    "                        re.match(r'^section\\s+\\d+', text.lower())):\n",
    "                        is_heading = True\n",
    "                        heading_level = 1\n",
    "                    elif re.match(r'^\\d+\\.\\d+\\.', text):\n",
    "                        is_heading = True\n",
    "                        heading_level = 2\n",
    "                    elif re.match(r'^\\d+\\.\\d+\\.\\d+\\.', text):\n",
    "                        is_heading = True\n",
    "                        heading_level = 3\n",
    "            \n",
    "            # Add element to the document structure\n",
    "            if is_heading:\n",
    "                document_structure['elements'].append({\n",
    "                    'content': text,\n",
    "                    'type': 'heading',\n",
    "                    'level': heading_level\n",
    "                })\n",
    "                self.stats['total_headings'] += 1\n",
    "                \n",
    "                # Check if heading is likely on first page\n",
    "                if i < 10:  # Assuming first ~10 paragraphs are first page\n",
    "                    first_page_headings_found = True\n",
    "                    self.stats['first_page_headings'] += 1\n",
    "            else:\n",
    "                # Check for highlighted or strikeout text\n",
    "                if any(run.bold for run in paragraph.runs):\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': text,\n",
    "                        'type': 'highlight'\n",
    "                    })\n",
    "                elif any(run.font.strike for run in paragraph.runs):\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': text,\n",
    "                        'type': 'strikeout'\n",
    "                    })\n",
    "                else:\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': text,\n",
    "                        'type': 'paragraph'\n",
    "                    })\n",
    "        \n",
    "        # Process tables\n",
    "        for table in document.tables:\n",
    "            # Convert table to pandas DataFrame\n",
    "            data = []\n",
    "            headers = []\n",
    "            \n",
    "            # Get headers from first row\n",
    "            if table.rows:\n",
    "                for cell in table.rows[0].cells:\n",
    "                    headers.append(cell.text.strip())\n",
    "            \n",
    "            # Get data from remaining rows\n",
    "            for row in table.rows[1:]:\n",
    "                row_data = []\n",
    "                for cell in row.cells:\n",
    "                    row_data.append(cell.text.strip())\n",
    "                data.append(row_data)\n",
    "            \n",
    "            # Create pandas DataFrame if possible\n",
    "            try:\n",
    "                if headers and data and len(headers) == len(data[0]):\n",
    "                    df = pd.DataFrame(data, columns=headers)\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': df,\n",
    "                        'type': 'table',\n",
    "                        'pandas_table': True\n",
    "                    })\n",
    "                else:\n",
    "                    # Create simple text representation for table\n",
    "                    table_text = \"Table content:\\n\"\n",
    "                    for row in table.rows:\n",
    "                        row_text = [cell.text.strip() for cell in row.cells]\n",
    "                        table_text += \" | \".join(row_text) + \"\\n\"\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': table_text,\n",
    "                        'type': 'table',\n",
    "                        'pandas_table': False\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                self._log_debug(f\"Error converting table to DataFrame: {e}\")\n",
    "                table_text = \"Table content (error converting):\\n\"\n",
    "                for row in table.rows:\n",
    "                    row_text = [cell.text.strip() for cell in row.cells]\n",
    "                    table_text += \" | \".join(row_text) + \"\\n\"\n",
    "                document_structure['elements'].append({\n",
    "                    'content': table_text,\n",
    "                    'type': 'table',\n",
    "                    'pandas_table': False\n",
    "                })\n",
    "        \n",
    "        # If no first page headings found, try to identify one\n",
    "        if not first_page_headings_found:\n",
    "            self._ensure_word_first_page_heading(document_structure)\n",
    "            \n",
    "        return document_structure\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"python-docx package not found. Please install it with 'pip install python-docx'\")\n",
    "        return {\n",
    "            'metadata': {'source': file_path, 'type': 'docx'},\n",
    "            'elements': [{\n",
    "                'content': f\"python-docx package required for Word processing: {file_path}\",\n",
    "                'type': 'paragraph',\n",
    "            }]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Word document: {e}\")\n",
    "        return {\n",
    "            'metadata': {'source': file_path, 'type': 'docx'},\n",
    "            'elements': [{\n",
    "                'content': f\"Error processing Word document: {file_path}. Error: {str(e)}\",\n",
    "                'type': 'paragraph',\n",
    "            }]\n",
    "        }\n",
    "\n",
    "def _ensure_word_first_page_heading(self, document_structure: Dict):\n",
    "    \"\"\"Make sure we have at least one heading identified from the first page of a Word doc.\"\"\"\n",
    "    first_few_elements = document_structure['elements'][:10]  # First ~10 elements likely from first page\n",
    "    \n",
    "    # Check if any heading in first few elements\n",
    "    if any(e['type'] == 'heading' for e in first_few_elements):\n",
    "        return\n",
    "        \n",
    "    # If not, look for a potential title in the first few paragraphs\n",
    "    for i, element in enumerate(first_few_elements):\n",
    "        if element['type'] == 'paragraph':\n",
    "            content = element['content']\n",
    "            # Check if this could be a title (short, no ending punctuation)\n",
    "            if len(content) < 80 and not any(p in content[-1:] for p in ['.', ',', ';', '?', '!']):\n",
    "                # Convert to heading\n",
    "                element['type'] = 'heading'\n",
    "                element['level'] = 1\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Converted first paragraph to heading: {content}\")\n",
    "                \n",
    "                # If document has title metadata, compare similarity\n",
    "                if 'title' in document_structure['metadata'] and document_structure['metadata']['title']:\n",
    "                    doc_title = document_structure['metadata']['title']\n",
    "                    if self._text_similarity(content, doc_title) > 0.7:\n",
    "                        self._log_debug(f\"Confirmed as title by metadata match: {content}\")\n",
    "                break\n",
    "\n",
    "def _text_similarity(self, text1, text2):\n",
    "    \"\"\"Calculate similarity between two text strings.\"\"\"\n",
    "    # Simple similarity measure based on word overlap\n",
    "    words1 = set(text1.lower().split())\n",
    "    words2 = set(text2.lower().split())\n",
    "    \n",
    "    if not words1 or not words2:\n",
    "        return 0\n",
    "        \n",
    "    intersection = words1.intersection(words2)\n",
    "    return len(intersection) / min(len(words1), len(words2))\n",
    "\n",
    "# Add methods to the EnhancedDocumentAnalyzer class\n",
    "EnhancedDocumentAnalyzer._process_word = _process_word\n",
    "EnhancedDocumentAnalyzer._ensure_word_first_page_heading = _ensure_word_first_page_heading\n",
    "EnhancedDocumentAnalyzer._text_similarity = _text_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaff2fc",
   "metadata": {},
   "source": [
    "### 3.1 Enhanced HTML Processing\n",
    "\n",
    "Let's improve the HTML processor to better detect headings, especially on the first page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe538f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_html(self, file_path: str) -> Dict:\n",
    "    \"\"\"Enhanced process for HTML documents with better heading detection.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'lxml')\n",
    "    document_structure = {\n",
    "        'metadata': {'source': file_path, 'type': 'html'},\n",
    "        'elements': []\n",
    "    }\n",
    "    \n",
    "    # Extract metadata from HTML head\n",
    "    try:\n",
    "        # Get title\n",
    "        if soup.title:\n",
    "            document_structure['metadata']['title'] = soup.title.string\n",
    "            \n",
    "        # Get meta description\n",
    "        meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "        if meta_desc:\n",
    "            document_structure['metadata']['description'] = meta_desc.get('content', '')\n",
    "            \n",
    "        # Get author\n",
    "        meta_author = soup.find('meta', attrs={'name': 'author'})\n",
    "        if meta_author:\n",
    "            document_structure['metadata']['author'] = meta_author.get('content', '')\n",
    "    except Exception as e:\n",
    "        self._log_debug(f\"Error extracting HTML metadata: {e}\")\n",
    "    \n",
    "    # First pass: look for explicit heading elements (h1-h6)\n",
    "    explicit_headings = []\n",
    "    for heading_level in range(1, 7):\n",
    "        for heading in soup.find_all(f'h{heading_level}'):\n",
    "            heading_text = heading.get_text().strip()\n",
    "            if heading_text:  # Skip empty headings\n",
    "                document_structure['elements'].append({\n",
    "                    'content': heading_text,\n",
    "                    'type': 'heading',\n",
    "                    'level': heading_level\n",
    "                })\n",
    "                explicit_headings.append(heading_text)\n",
    "                self.stats['total_headings'] += 1\n",
    "    \n",
    "    # Second pass: look for other elements that might be headings\n",
    "    # Focus on first few elements for first-page headings\n",
    "    elements_processed = 0\n",
    "    found_first_heading = False\n",
    "    \n",
    "    # Check for title in first div/header if no h1 found\n",
    "    if not any(h['level'] == 1 for h in document_structure['elements'] if h['type'] == 'heading'):\n",
    "        # Look in header, div.header, or first major div\n",
    "        header_candidates = [\n",
    "            soup.find('header'),\n",
    "            soup.find('div', class_='header'),\n",
    "            soup.find('div', id='header'),\n",
    "            soup.find('div', class_='title'),\n",
    "            soup.find('div', class_='main-title')\n",
    "        ]\n",
    "        \n",
    "        for candidate in header_candidates:\n",
    "            if candidate:\n",
    "                # Skip if we already captured this in explicit headings\n",
    "                candidate_text = candidate.get_text().strip()\n",
    "                if not candidate_text or candidate_text in explicit_headings:\n",
    "                    continue\n",
    "                    \n",
    "                # Look for large text or strong/b elements\n",
    "                potential_title = candidate.find(['strong', 'b', 'span', 'div'])\n",
    "                if potential_title:\n",
    "                    title_text = potential_title.get_text().strip()\n",
    "                    if title_text and len(title_text) < 100:\n",
    "                        document_structure['elements'].insert(0, {\n",
    "                            'content': title_text,\n",
    "                            'type': 'heading',\n",
    "                            'level': 1,\n",
    "                            'extracted_from': 'header'\n",
    "                        })\n",
    "                        found_first_heading = True\n",
    "                        self.stats['first_page_headings'] += 1\n",
    "                        self.stats['total_headings'] += 1\n",
    "                        self.stats['missed_headings_recovered'] += 1\n",
    "                        break\n",
    "                        \n",
    "                # If no specific element found, use the header text itself\n",
    "                if not found_first_heading and len(candidate_text) < 100:\n",
    "                    document_structure['elements'].insert(0, {\n",
    "                        'content': candidate_text,\n",
    "                        'type': 'heading',\n",
    "                        'level': 1,\n",
    "                        'extracted_from': 'header_text'\n",
    "                    })\n",
    "                    found_first_heading = True\n",
    "                    self.stats['first_page_headings'] += 1\n",
    "                    self.stats['total_headings'] += 1\n",
    "                    self.stats['missed_headings_recovered'] += 1\n",
    "                    break\n",
    "    \n",
    "    # Extract paragraphs\n",
    "    for para in soup.find_all('p'):\n",
    "        elements_processed += 1\n",
    "        is_first_page = elements_processed < 10  # Simple heuristic for first page\n",
    "        \n",
    "        # Check for highlighted text\n",
    "        highlighted = para.find_all(['strong', 'b', 'mark', 'em'])\n",
    "        strikeout = para.find_all('s')\n",
    "        \n",
    "        if highlighted:\n",
    "            for h in highlighted:\n",
    "                document_structure['elements'].append({\n",
    "                    'content': h.get_text(),\n",
    "                    'type': 'highlight',\n",
    "                })\n",
    "        \n",
    "        if strikeout:\n",
    "            for s in strikeout:\n",
    "                document_structure['elements'].append({\n",
    "                    'content': s.get_text(),\n",
    "                    'type': 'strikeout',\n",
    "                })\n",
    "        \n",
    "        # Add the full paragraph\n",
    "        para_text = para.get_text().strip()\n",
    "        if not para_text:\n",
    "            continue\n",
    "            \n",
    "        # Check if this might be a missed heading (early in document, short, etc.)\n",
    "        if not found_first_heading and is_first_page:\n",
    "            # Short paragraphs near the top that might be headings\n",
    "            if len(para_text) < 80 and not any(p in para_text for p in ['.', ',', ';', '?', '!']):\n",
    "                # Likely a heading if it's short without punctuation\n",
    "                document_structure['elements'].append({\n",
    "                    'content': para_text,\n",
    "                    'type': 'heading',\n",
    "                    'level': 1 if elements_processed < 3 else 2,\n",
    "                    'extracted_from': 'first_paragraph'\n",
    "                })\n",
    "                found_first_heading = True\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                continue\n",
    "            \n",
    "            # Check for CSS class that suggests heading\n",
    "            css_classes = para.get('class', [])\n",
    "            for css_class in css_classes:\n",
    "                if 'title' in css_class.lower() or 'heading' in css_class.lower():\n",
    "                    document_structure['elements'].append({\n",
    "                        'content': para_text,\n",
    "                        'type': 'heading',\n",
    "                        'level': 1 if 'title' in css_class.lower() else 2,\n",
    "                        'extracted_from': 'css_class'\n",
    "                    })\n",
    "                    found_first_heading = True\n",
    "                    self.stats['first_page_headings'] += 1\n",
    "                    self.stats['total_headings'] += 1\n",
    "                    self.stats['missed_headings_recovered'] += 1\n",
    "                    continue\n",
    "        \n",
    "        # Normal paragraph\n",
    "        document_structure['elements'].append({\n",
    "            'content': para_text,\n",
    "            'type': 'paragraph',\n",
    "        })\n",
    "    \n",
    "    # Extract tables\n",
    "    for table in soup.find_all('table'):\n",
    "        # Convert HTML table to pandas DataFrame\n",
    "        table_data = []\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all(['td', 'th'])\n",
    "            cols = [ele.get_text().strip() for ele in cols]\n",
    "            table_data.append(cols)\n",
    "        \n",
    "        if table_data:\n",
    "            # Try to create a pandas DataFrame\n",
    "            try:\n",
    "                df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
    "                document_structure['elements'].append({\n",
    "                    'content': df,\n",
    "                    'type': 'table',\n",
    "                    'pandas_table': True\n",
    "                })\n",
    "            except:\n",
    "                # Fallback to string representation\n",
    "                document_structure['elements'].append({\n",
    "                    'content': str(table_data),\n",
    "                    'type': 'table',\n",
    "                    'pandas_table': False\n",
    "                })\n",
    "    \n",
    "    # Extract images\n",
    "    for img in soup.find_all('img'):\n",
    "        alt_text = img.get('alt', 'Image')\n",
    "        src = img.get('src', '')\n",
    "        document_structure['elements'].append({\n",
    "            'content': f\"{alt_text} (src: {src})\",\n",
    "            'type': 'image',\n",
    "        })\n",
    "        \n",
    "        # Check if this image might have a caption that's actually a heading\n",
    "        if img.parent and (img.parent.name in ['figure', 'div'] and img.parent.find('figcaption')):\n",
    "            caption = img.parent.find('figcaption').get_text().strip()\n",
    "            if len(caption) < 80 and not found_first_heading and elements_processed < 5:\n",
    "                # This could be a title with image\n",
    "                document_structure['elements'].append({\n",
    "                    'content': caption,\n",
    "                    'type': 'heading',\n",
    "                    'level': 1,\n",
    "                    'extracted_from': 'image_caption'\n",
    "                })\n",
    "                found_first_heading = True\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "    \n",
    "    # If still no first page heading found, try to use document title\n",
    "    if not found_first_heading and 'title' in document_structure['metadata']:\n",
    "        title = document_structure['metadata']['title']\n",
    "        if title and len(title) < 100:\n",
    "            document_structure['elements'].insert(0, {\n",
    "                'content': title,\n",
    "                'type': 'heading',\n",
    "                'level': 1,\n",
    "                'extracted_from': 'metadata_title'\n",
    "            })\n",
    "            self.stats['first_page_headings'] += 1\n",
    "            self.stats['total_headings'] += 1\n",
    "            self.stats['missed_headings_recovered'] += 1\n",
    "    \n",
    "    return document_structure\n",
    "\n",
    "# Add method to the EnhancedDocumentAnalyzer class\n",
    "EnhancedDocumentAnalyzer._process_html = _process_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fced7f",
   "metadata": {},
   "source": [
    "### 3.3 Enhanced Plain Text/Markdown Processing\n",
    "\n",
    "Let's improve the processing of plain text and markdown files to better identify headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d6272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_text(self, file_path: str) -> Dict:\n",
    "    \"\"\"Enhanced process for plain text or markdown documents with better heading detection.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    document_structure = {\n",
    "        'metadata': {'source': file_path, 'type': 'text'},\n",
    "        'elements': []\n",
    "    }\n",
    "    \n",
    "    # Determine if this is likely markdown\n",
    "    is_markdown = file_path.lower().endswith('.md') or '# ' in content or '## ' in content\n",
    "    \n",
    "    # Find potential title from first line\n",
    "    found_first_heading = False\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    if lines and lines[0].strip():\n",
    "        first_line = lines[0].strip()\n",
    "        # Check if first line is already a markdown heading\n",
    "        if first_line.startswith('#'):\n",
    "            found_first_heading = True\n",
    "        elif len(first_line) < 80 and not any(p in first_line for p in ['.', ',', ';', '?', '!']):\n",
    "            # First line looks like a title - add it as heading\n",
    "            document_structure['elements'].append({\n",
    "                'content': first_line,\n",
    "                'type': 'heading',\n",
    "                'level': 1,\n",
    "                'extracted_from': 'first_line'\n",
    "            })\n",
    "            found_first_heading = True\n",
    "            self.stats['first_page_headings'] += 1\n",
    "            self.stats['total_headings'] += 1\n",
    "            self.stats['missed_headings_recovered'] += 1\n",
    "    \n",
    "    # Split by double newlines to separate paragraphs\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "    \n",
    "    # Track if we're still in the \"first page\" (first few paragraphs)\n",
    "    is_first_page = True\n",
    "    paragraph_count = 0\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        para = para.strip()\n",
    "        if not para:\n",
    "            continue\n",
    "            \n",
    "        paragraph_count += 1\n",
    "        if paragraph_count > 10:\n",
    "            is_first_page = False\n",
    "        \n",
    "        # Check if it's a heading (starts with # in markdown)\n",
    "        if para.startswith('#'):\n",
    "            level = len(re.match(r'^#+', para).group())\n",
    "            heading_text = para.lstrip('#').strip()\n",
    "            document_structure['elements'].append({\n",
    "                'content': heading_text,\n",
    "                'type': 'heading',\n",
    "                'level': level\n",
    "            })\n",
    "            self.stats['total_headings'] += 1\n",
    "            if is_first_page:\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                found_first_heading = True\n",
    "        \n",
    "        # Check for alternative heading formats (underlined with === or ---)\n",
    "        elif paragraph_count < len(paragraphs) - 1:\n",
    "            next_para = paragraphs[paragraph_count].strip()\n",
    "            if next_para and (all(c == '=' for c in next_para) or all(c == '-' for c in next_para)):\n",
    "                # This is a heading underlined with === or ---\n",
    "                level = 1 if '=' in next_para else 2\n",
    "                document_structure['elements'].append({\n",
    "                    'content': para,\n",
    "                    'type': 'heading',\n",
    "                    'level': level\n",
    "                })\n",
    "                self.stats['total_headings'] += 1\n",
    "                if is_first_page:\n",
    "                    self.stats['first_page_headings'] += 1\n",
    "                    found_first_heading = True\n",
    "                continue  # Skip the underline row\n",
    "                \n",
    "        # Check if it's a table (simple detection for markdown tables)\n",
    "        elif '|' in para and '-+-' in para.replace('|', '+'):\n",
    "            document_structure['elements'].append({\n",
    "                'content': para,\n",
    "                'type': 'table',\n",
    "                'pandas_table': False\n",
    "            })\n",
    "            \n",
    "        # Check for strikeout text (~~text~~ in markdown)\n",
    "        elif '~~' in para:\n",
    "            document_structure['elements'].append({\n",
    "                'content': para,\n",
    "                'type': 'strikeout',\n",
    "            })\n",
    "            \n",
    "        # Check for highlighted text (** or __ in markdown)\n",
    "        elif '**' in para or '__' in para:\n",
    "            document_structure['elements'].append({\n",
    "                'content': para,\n",
    "                'type': 'highlight',\n",
    "            })\n",
    "            \n",
    "        # Check for numbered headings or other patterns that suggest headings\n",
    "        elif is_first_page and not found_first_heading and (\n",
    "            re.match(r'^(\\d+\\.)+\\s+', para) or  # Numbered heading like \"1.2.3 Title\"\n",
    "            re.match(r'^(Chapter|Section|Title|Part)\\s+\\d+', para, re.IGNORECASE)  # Named headings\n",
    "        ):\n",
    "            document_structure['elements'].append({\n",
    "                'content': para,\n",
    "                'type': 'heading',\n",
    "                'level': 1 if paragraph_count <= 2 else 2,\n",
    "                'extracted_from': 'numbered_pattern'\n",
    "            })\n",
    "            self.stats['first_page_headings'] += 1\n",
    "            self.stats['total_headings'] += 1\n",
    "            self.stats['missed_headings_recovered'] += 1\n",
    "            found_first_heading = True\n",
    "            \n",
    "        # Regular paragraph\n",
    "        else:\n",
    "            document_structure['elements'].append({\n",
    "                'content': para,\n",
    "                'type': 'paragraph',\n",
    "            })\n",
    "    \n",
    "    # If we haven't found a first page heading and this isn't markdown, try harder\n",
    "    if not found_first_heading and not is_markdown:\n",
    "        self._ensure_text_first_page_heading(document_structure)\n",
    "    \n",
    "    return document_structure\n",
    "\n",
    "def _ensure_text_first_page_heading(self, document_structure: Dict):\n",
    "    \"\"\"Make sure we have at least one heading from a plain text document.\"\"\"\n",
    "    # Look at the first few elements\n",
    "    first_elements = document_structure['elements'][:5]\n",
    "    \n",
    "    for i, element in enumerate(first_elements):\n",
    "        if element['type'] == 'paragraph':\n",
    "            text = element['content']\n",
    "            \n",
    "            # First paragraph is often a title in plain text documents\n",
    "            if i == 0 and len(text) < 80:\n",
    "                element['type'] = 'heading'\n",
    "                element['level'] = 1\n",
    "                element['extracted_from'] = 'first_paragraph'\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Converted first paragraph to heading: {text}\")\n",
    "                return\n",
    "                \n",
    "            # Check for ALL CAPS paragraphs (often headings)\n",
    "            if text.isupper() and 5 < len(text) < 80:\n",
    "                element['type'] = 'heading'\n",
    "                element['level'] = 1 if i < 2 else 2\n",
    "                element['extracted_from'] = 'all_caps'\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Converted all caps paragraph to heading: {text}\")\n",
    "                return\n",
    "                \n",
    "            # Check for centered text (approximated by leading/trailing spaces)\n",
    "            if text.startswith('    ') and text.rstrip().endswith('    '):\n",
    "                element['type'] = 'heading'\n",
    "                element['level'] = 1\n",
    "                element['extracted_from'] = 'centered_text'\n",
    "                self.stats['first_page_headings'] += 1\n",
    "                self.stats['total_headings'] += 1\n",
    "                self.stats['missed_headings_recovered'] += 1\n",
    "                self._log_debug(f\"Converted centered paragraph to heading: {text}\")\n",
    "                return\n",
    "\n",
    "# Add methods to the EnhancedDocumentAnalyzer class\n",
    "EnhancedDocumentAnalyzer._process_text = _process_text\n",
    "EnhancedDocumentAnalyzer._ensure_text_first_page_heading = _ensure_text_first_page_heading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aeaf5a",
   "metadata": {},
   "source": [
    "## 4. Process Different Document Types\n",
    "\n",
    "Now let's create a demonstration function that processes different document types and reports on the improvements in heading detection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
