{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b378ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install spacy --quiet\n",
    "python -m spacy download en_core_web_sm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eff691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504fc7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003c6ab",
   "metadata": {},
   "source": [
    "### Simple intent classifier\n",
    "- Defining some sample intent patterns\n",
    "- Checking the intent matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b581efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(text):\n",
    "    \"\"\"\n",
    "    Classify the intent of the given text using spaCy's NLP model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to classify.\n",
    "        \n",
    "    Returns:\n",
    "        str: The classified intent.\n",
    "    \"\"\"\n",
    "    intent_patterns = {\n",
    "        'greeting': ['hello', 'hi', 'hey', \"greetings\"],\n",
    "        'goodbye': ['bye', 'goodbye', 'see you', 'farewell'],\n",
    "        'booking': ['book', 'reserve', 'schedule'],\n",
    "        'weather': ['weather', 'forecast', 'temperature'],\n",
    "        'order_food': ['order', 'food', 'meal', 'dinner', 'buy', 'get']\n",
    "    }\n",
    "\n",
    "    for intent, patterns in intent_patterns.items():\n",
    "        if any(pattern in text for pattern in patterns):\n",
    "            return intent\n",
    "    return 'unknown'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd92cc54",
   "metadata": {},
   "source": [
    "### Entity extractor\n",
    "- Extracting entities from the text using spacy\n",
    "- Getting named entities recognized by spacy\n",
    "- Extracting dates, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4d11057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    \"\"\"\n",
    "    Extract entities from the given text using spaCy's NLP model.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to extract entities from.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of extracted entities.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    entities = {}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities[ent.label_] = ent.text\n",
    "\n",
    "    for token in doc:\n",
    "        if token.like_num:\n",
    "            entities['number'] = token.text\n",
    "    \n",
    "    return entities\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb461a",
   "metadata": {},
   "source": [
    "### Processing the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e0bffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentence(text):\n",
    "    \"\"\"\n",
    "    Analyze the given text to classify its intent and extract entities.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the classified intent and extracted entities.\n",
    "    \"\"\"\n",
    "    intent = classify_intent(text)\n",
    "    entities = extract_entities(text)\n",
    "    \n",
    "    return {\n",
    "        'intent': intent,\n",
    "        'entities': entities\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c106bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"Hello, I would like to book a table for two.\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Book a flight to Paris next Monday.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fccec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello, I would like to book a table for two.\n",
      "Intent: greeting\n",
      "Entities: {'CARDINAL': 'two', 'number': 'two'}\n",
      "\n",
      "Text: What's the weather like today?\n",
      "Intent: weather\n",
      "Entities: {'DATE': 'today'}\n",
      "\n",
      "Text: Book a flight to Paris next Monday.\n",
      "Intent: booking\n",
      "Entities: {'GPE': 'paris', 'DATE': 'next monday'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in sample_texts:\n",
    "    text_lower = text.lower()\n",
    "    result = analyze_sentence(text_lower)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Intent: {result['intent']}\")\n",
    "    print(f\"Entities: {result['entities']}\\n\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f5e23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d13bec9b",
   "metadata": {},
   "source": [
    "Collecting workspace information# Intent and Entity Recognition Documentation\n",
    "\n",
    "This document provides an overview of the Natural Language Understanding (NLU) module implemented in the nlu.ipynb file.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The NLU module uses spaCy to perform two main tasks:\n",
    "1. Intent classification - detecting the purpose of a user's message\n",
    "2. Entity extraction - identifying important information pieces in text\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- [spaCy](https://spacy.io/) library\n",
    "- English language model (`en_core_web_sm`)\n",
    "\n",
    "## Main Components\n",
    "\n",
    "### 1. Intent Classifier\n",
    "\n",
    "The `classify_intent` function determines the user's intent by matching keywords in the input text against predefined patterns.\n",
    "\n",
    "Supported intents:\n",
    "- **greeting**: hello, hi, hey, greetings\n",
    "- **goodbye**: bye, goodbye, see you, farewell\n",
    "- **booking**: book, reserve, schedule\n",
    "- **weather**: weather, forecast, temperature\n",
    "- **order_food**: order, food, meal, dinner, buy, get\n",
    "- **unknown**: default when no patterns match\n",
    "\n",
    "### 2. Entity Extractor\n",
    "\n",
    "The `extract_entities` function identifies and extracts named entities and numeric values from the input text.\n",
    "\n",
    "Entity types extracted:\n",
    "- Named entities recognized by spaCy (locations, dates, organizations, etc.)\n",
    "- Numeric values (marked as 'number')\n",
    "\n",
    "### 3. Sentence Analyzer\n",
    "\n",
    "The `analyze_sentence` function combines intent classification and entity extraction to provide complete analysis of user input.\n",
    "\n",
    "Returns:\n",
    "- The classified intent\n",
    "- A dictionary of extracted entities with their types\n",
    "\n",
    "## Usage Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Book a flight to Paris next Monday\"\n",
    "text_lower = text.lower()\n",
    "result = analyze_sentence(text_lower)\n",
    "\n",
    "# Result:\n",
    "# Intent: booking\n",
    "# Entities: {'GPE': 'paris', 'DATE': 'next monday'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecfb63e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Processing Flow\n",
    "\n",
    "1. Text is lowercased for consistent processing\n",
    "2. Intent is classified based on keyword matching\n",
    "3. Entities are extracted using spaCy's NLP capabilities\n",
    "4. Results are combined into a single analysis output\n",
    "\n",
    "## Sample Results\n",
    "\n",
    "| Input Text | Detected Intent | Extracted Entities |\n",
    "|------------|----------------|-------------------|\n",
    "| \"Hello, I would like to book a table for two.\" | greeting | {'CARDINAL': 'two', 'number': 'two'} |\n",
    "| \"What's the weather like today?\" | weather | {'DATE': 'today'} |\n",
    "| \"Book a flight to Paris next Monday.\" | booking | {'GPE': 'paris', 'DATE': 'next monday'} |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
